import re
import time
import logging
import os
import json
from models.cifti import *
from models.cifti_matrix import *
from models.paths import *

BATCHES_DIRNAME = "batches"

class Analysis():
    """SuperClass for Specific analyses such as Mplus, Palm, etc

    Standardizes treatment of config file information and structuring of output directories"""

    def __init__(self, config, module_name, filename=""):

        # this will be used when saving/loading files to indicate which kind of analysis it is
        self.module_name = module_name
        self.config = config
        default_output_dir = self.config._data.get("output_dir", "")
        self.paths = Paths(default_output_dir)
        self.required_config_keys = []
        self.filename = filename
        self.execution_history = []
        self.cancelling = False
        self.batchTitle = ""

    @property
    def output_dir(self):
        return self.paths.root

    @output_dir.setter
    def output_dir(self, path):
        self.paths.root = path

    @property
    def batches_dir(self):
        return self.paths.batches_dir


    def batches(self):
        return self.paths.batches()

    def missingRequiredConfigKeys(self):

        return self.config.missing_keys(self.required_config_keys)

    def configValidationErrors(self):
        missing = self.missingRequiredConfigKeys()
        missing = [(m, "Missing Key") for m in missing]
        invalid_directories = self.config.resolve_directories(['output_dir'])
        # problems are returned, and empty return valid is good
        return missing + invalid_directories

    def setBatchTitle(self, raw_title):
        #todo this is moving towards obsolete as refactor path functionality into paths.py

        self.batchTitle = re.sub('[^0-9a-zA-Z]+', '_', self.dir_name_for_title(raw_title))

    def progressMessage(self, txt):

        logging.info(txt)
        if self.progress_callback is not None:
            self.progress_callback.emit(txt)

    def save(self, filename):

        save_data = {"title": "mytitle", "module": self.module_name, "version": 0.1,
                     "execution_history": self.execution_history}

        save_data["batchTitle"] = self.batchTitle
        save_data["output_dir"] = self.output_dir

        if hasattr(self, 'template'):
            template = self.template
            if hasattr(template, 'data'):
                save_data['template'] = self.template.data

        self.module_specific_save_data(save_data)

        with open(filename, "w") as f:
            json.dump(save_data, f)

    def module_specific_save_data(self, save_data):
        """override in subclasses, add any attributes to save_data dictionary that should be included in the saved json file"""
        print(
            "override in subclasses, add any attributes to save_data dictionary that should be included in the saved json file")

    def add_execution_history(self, output_dir, limit_by_voxel, limit_by_row):
        history_record = {"output_dir": output_dir, "limit_by_voxel": limit_by_voxel, "limit_by_row": limit_by_row}
        self.execution_history.append(history_record)

    def base_cifti_for_output(self):
        output_cifti = Cifti(self.config._data["Base_cifti_for_output"])

        output_cifti.nullify()

        return output_cifti

    def generate_ciftis_from_csv(self, csv_path):
        data = pd.read_csv(csv_path)
        self.generate_ciftis_from_dataframe(data)

    def generate_ciftis_from_dataframe(self, data):

        for c in data.columns:
            cifti = self.base_cifti_for_output()
            cifti.setVector(data[c])
            filename = c + ".dscalar.nii"
            cifti_output_path =  self.paths.batch_cifits_path(filename)
            cifti.save(cifti_output_path)

    @property
    def data_filename(self):
        return "input.csv"

    def scrubbed_data_path(self):
        """
        path to the file of date generated by the application for feeding into the underlying analysis tool
        i.e. for Mplus, the smaller csv file that contains only the columns needed, appropriate treatment for missing data,
        and when necessary the added voxel data
        :return: full path to the appropriate file
        """
        return self.paths.batch_inputs_path(self.data_filename)

    def process_load_data(self, load_data):

        keys_to_copy = ["output_dir"]
        for key in keys_to_copy:
            if key in load_data:
                #careful to use the __setattr__ instead of just setattr or we don't
                #end up getting any customer property setters called
                self.__setattr__(key, load_data[key])
                #setattr(self, )
